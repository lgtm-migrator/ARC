{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import urllib\n",
    "from collections import OrderedDict\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from cookielib import CookieJar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cookie jar to store cookies\n",
    "cj = CookieJar()\n",
    "opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make simple function to get webpage and soup\n",
    "def get(url, data=None):\n",
    "    response = opener.open(url, data=data)\n",
    "\n",
    "    return BeautifulSoup(response, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for experimental data on the species page\n",
    "def get_expt(spc_soup):\n",
    "    rows = spc_soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        for i, column in enumerate(columns):\n",
    "            if column.get_text().strip() == 'Enthalpy 298.15K':\n",
    "                # Next column is experimental data\n",
    "                next_column = columns[i + 1]\n",
    "                if 'x' in next_column.get_text():\n",
    "                    return base_url + next_column.a['href']\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for InChI from experimental data page\n",
    "def get_inchi(expt_soup):\n",
    "    rows = expt_soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        for column in columns:\n",
    "            text = column.get_text().strip()\n",
    "            if 'InChI=' in text:\n",
    "                return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for H298 data from experimental data page\n",
    "def get_h(expt_soup):\n",
    "    rows = expt_soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        for i, column in enumerate(columns):\n",
    "            if column.get_text().strip() == 'Hfg(298.15K)':\n",
    "                # Next three columns are value, uncertainty, and units\n",
    "                return (columns[i + 1].get_text().strip(), columns[i + 2].get_text().strip(), columns[i + 3].get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://cccbdb.nist.gov/'\n",
    "list_url = base_url + 'listallx.asp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve full species list\n",
    "list_soup = get(list_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parse links to species pages from list\n",
    "links = list_soup.find_all('a')\n",
    "\n",
    "spc_list = OrderedDict()\n",
    "for link in links:\n",
    "    if link.has_attr('href') and 'casno=' in link['href']:\n",
    "        target = link['href']\n",
    "        # It seems that some link to old data page? Replace with new link for consistency\n",
    "        target = target.replace('alldata2.asp', 'alldata2x.asp')\n",
    "        spc_list[link.get_text()] = target\n",
    "\n",
    "print len(spc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a normal request to set up cookies properly\n",
    "# For some reason, following links on the species list page doesn't work unless you do a normal search first\n",
    "data = urllib.urlencode({'formula': 'H', 'SUBMIT1': 'Submit'})\n",
    "form_url = 'https://cccbdb.nist.gov/getformx.asp'\n",
    "test_soup = get(form_url, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try getting experimental data for every species in the list\n",
    "errors = OrderedDict()\n",
    "all_data = []\n",
    "for i, (name, partial_url) in enumerate(spc_list.iteritems()):\n",
    "    if 'ion' in name.lower():\n",
    "        # Skip ions (?)\n",
    "        continue\n",
    "    spc_url = base_url + partial_url\n",
    "    try:\n",
    "        spc_soup = get(spc_url)\n",
    "    except urllib2.HTTPError as e:\n",
    "        # Server error, might work if we try again later, so save the species\n",
    "        errors[name] = partial_url\n",
    "        print name + ' - ' + e.message\n",
    "        continue\n",
    "    expt_url = get_expt(spc_soup)\n",
    "    if expt_url:\n",
    "        expt_soup = get(expt_url)\n",
    "        inchi = get_inchi(expt_soup)\n",
    "        value, uncertainty, units = get_h(expt_soup)\n",
    "        if value:\n",
    "            value = float(value)\n",
    "        else:\n",
    "            value = None\n",
    "        if uncertainty:\n",
    "            uncertainty = float(uncertainty)\n",
    "        else:\n",
    "            uncertainty = None\n",
    "        all_data.append([inchi, value, uncertainty, units])\n",
    "        print name + ' - found expt data'\n",
    "    else:\n",
    "        print name + ' - no expt data found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
